{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercício 10_11 RAGAS\n",
    "\n",
    "matheusrdgsf@gmail.com / mrsf@cin.ufpe.br"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install groq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import getpass\n",
    "import os\n",
    "import string\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import torch\n",
    "from datasets import load_dataset\n",
    "from groq import Groq\n",
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "from tqdm.notebook import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "N_QUESTIONS = 150"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LLM Inferecene"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "GROQ_KEY = os.getenv(\"GROQ_KEY\", getpass.getpass(\"Enter your Groq API key: \"))\n",
    "client = Groq(\n",
    "    api_key=GROQ_KEY,\n",
    ")\n",
    "MODELS = [\"llama3-70b-8192\", \"llama3-8b-8192\", \"mixtral-8x7b-32768\", \"gemma-7b-it\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_groq(text, retry=10, temperature=0):\n",
    "\n",
    "    for _ in range(retry):\n",
    "        try:\n",
    "            chat_completion = client.chat.completions.create(\n",
    "                messages=[\n",
    "                    {\n",
    "                        \"role\": \"user\",\n",
    "                        \"content\": f\"{text}\",\n",
    "                    }\n",
    "                ],\n",
    "                model=MODELS[0],\n",
    "                seed=42,\n",
    "                temperature=temperature,\n",
    "            )\n",
    "\n",
    "            return chat_completion.choices[0].message.content\n",
    "        except Exception as e:\n",
    "            print(e)\n",
    "            pass\n",
    "\n",
    "    return \"Fail in GROQ API.\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = load_dataset(\"json\", data_files=\"data/test_questions.json\")[\"train\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'answer': {'answer_spans': None,\n",
       "  'answer_unit': 'years',\n",
       "  'answer_value': '5',\n",
       "  'type': 'value'},\n",
       " 'question_links': ['World War I'],\n",
       " 'title': 'Giovanni Messe',\n",
       " 'context': [{'indices': [528, 615],\n",
       "   'passage': 'main',\n",
       "   'text': 'he became aide-de-camp to King Victor Emmanuel III, holding this post from 1923 to 1927'},\n",
       "  {'indices': [178, 262],\n",
       "   'passage': 'World War I',\n",
       "   'text': 'a global war originating in Europe that lasted from 28 July 1914 to 11 November 1918'}],\n",
       " 'question': 'How long had the First World War been over when Messe was named aide-de-camp?'}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Process data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_processed = []\n",
    "\n",
    "for sample in data:\n",
    "    question = sample[\"question\"].strip()\n",
    "    answer = sample[\"answer\"]\n",
    "    context = sample[\"context\"]\n",
    "\n",
    "    if answer[\"type\"] == \"binary\":\n",
    "        answer_text = answer[\"answer_value\"]\n",
    "    elif answer[\"type\"] == \"value\":\n",
    "        answer_text = answer[\"answer_value\"] + \" \" + answer[\"answer_unit\"]\n",
    "    elif answer[\"type\"] == \"span\":\n",
    "        answer_text = answer[\"answer_spans\"][0][\"text\"]\n",
    "    elif answer[\"type\"] == \"none\":\n",
    "        answer_text = \"none\"\n",
    "    else:\n",
    "        print(\"Unknown answer type\")\n",
    "\n",
    "    context = [i[\"text\"] for i in context]\n",
    "\n",
    "    data_processed.append(\n",
    "        {\"question\": question, \"answer\": answer_text.strip(), \"context\": context}\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'question': 'How long had the First World War been over when Messe was named aide-de-camp?',\n",
       " 'answer': '5 years',\n",
       " 'context': ['he became aide-de-camp to King Victor Emmanuel III, holding this post from 1923 to 1927',\n",
       "  'a global war originating in Europe that lasted from 28 July 1914 to 11 November 1918']}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_processed[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RAGAS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Faithfulness\n",
    "\n",
    "We can advance directly to second step because of the question lenghts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "if os.path.exists(\"faithfulness_checkpoint.csv\"):\n",
    "    faithfulness_checkpoint = pd.read_csv(\"faithfulness_checkpoint.csv\")\n",
    "else:\n",
    "    faithfulness_checkpoint = pd.DataFrame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_faithfulness = \"\"\"\n",
    "Consider the given context and following statements, then determine whether they are supported by the information present in the context. Provide a brief explanation for each statement before arriving at the verdict (Yes/No). Provide a final verdict for each statement in order at the end in the given format. Do not deviate from the specified format.\n",
    "\n",
    "statement: {statement}\n",
    "context: {context}\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e67879e059454e0d892773af36f2b3d0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "indices_to_process = [\n",
    "    i for i in range(len(data_processed)) if i not in faithfulness_checkpoint.index\n",
    "]\n",
    "\n",
    "for i in tqdm(indices_to_process, total=len(indices_to_process)):\n",
    "\n",
    "    sample = data_processed[i]\n",
    "\n",
    "    question = sample[\"question\"]\n",
    "    answer = sample[\"answer\"]\n",
    "    context = sample[\"context\"]\n",
    "\n",
    "    prompt = prompt_faithfulness.format(statement=question, context=\" \".join(context))\n",
    "\n",
    "    prediction = predict_groq(prompt).lower().strip()\n",
    "\n",
    "    faithfulness_checkpoint = pd.concat(\n",
    "        [\n",
    "            faithfulness_checkpoint,\n",
    "            pd.DataFrame(\n",
    "                {\n",
    "                    \"question\": [question],\n",
    "                    \"answer\": [answer],\n",
    "                    \"context\": [context],\n",
    "                    \"prediction\": [prediction],\n",
    "                }\n",
    "            ),\n",
    "        ],\n",
    "        ignore_index=True,\n",
    "    )\n",
    "\n",
    "    faithfulness_checkpoint.to_csv(\"faithfulness_checkpoint.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# regex to find verdict\n",
    "import re\n",
    "\n",
    "verdict_regex = re.compile(r\"verdict: (yes|no)\")\n",
    "\n",
    "faithfulness_checkpoint[\"verdict\"] = faithfulness_checkpoint[\"prediction\"].apply(\n",
    "    lambda x: verdict_regex.search(x).group(1) if verdict_regex.search(x) else None\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Faithfulness: 70.00%\n"
     ]
    }
   ],
   "source": [
    "print(\n",
    "    f\"Faithfulness: {faithfulness_checkpoint['verdict'].value_counts().get('yes', 0) / faithfulness_checkpoint.shape[0] * 100:.2f}%\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Answer Relevance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "if os.path.exists(\"answer_relevance_checkpoint.csv\"):\n",
    "    answer_relevance_checkpoint = pd.read_csv(\"answer_relevance_checkpoint.csv\")\n",
    "else:\n",
    "    answer_relevance_checkpoint = pd.DataFrame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_answer_relevance = \"\"\"\n",
    "Generate {n_questions} different questions for the given answer.\n",
    "\n",
    "Your answer need to be only the questions split by \\n. Don't add any other information or special characters.\n",
    "\n",
    "Do not deviate from the specified format.\n",
    "answer: {answer}\n",
    "\"\"\"\n",
    "\n",
    "retry_prompt = \"\"\"\n",
    "Given the following questions, split them in {n_questions} and return splitted by \\n.\n",
    "Don't add any other information or special characters.\n",
    "\n",
    "questions: {questions}\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Generate Questions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a692fd0da2974529a03740253b21e37d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/50 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "N_QUESTIONS = 5\n",
    "\n",
    "total_process = len(data_processed) - len(answer_relevance_checkpoint)\n",
    "\n",
    "start_index = len(answer_relevance_checkpoint)\n",
    "\n",
    "for i in tqdm(range(start_index, len(data_processed)), total=total_process):\n",
    "    row = data_processed[i]\n",
    "\n",
    "    prompt = prompt_answer_relevance.format(\n",
    "        answer=row[\"answer\"], n_questions=N_QUESTIONS\n",
    "    )\n",
    "\n",
    "    questions = predict_groq(prompt, temperature=1).split(\"\\n\")\n",
    "\n",
    "    if len(questions) != N_QUESTIONS:\n",
    "        questions = predict_groq(\n",
    "            retry_prompt.format(\n",
    "                n_questions=N_QUESTIONS,\n",
    "                questions=questions,\n",
    "                temperature=1,\n",
    "            )\n",
    "        ).split(\"\\n\")\n",
    "\n",
    "    answer_relevance_checkpoint = pd.concat(\n",
    "        [\n",
    "            answer_relevance_checkpoint,\n",
    "            pd.DataFrame(\n",
    "                {\n",
    "                    \"answer\": row[\"answer\"],\n",
    "                    \"questions\": [questions],\n",
    "                    \"original_question\": row[\"question\"],\n",
    "                }\n",
    "            ),\n",
    "        ],\n",
    "        ignore_index=True,\n",
    "    )\n",
    "\n",
    "    answer_relevance_checkpoint.to_csv(\"answer_relevance_checkpoint.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Extract Answers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "cosine_similarity = torch.nn.CosineSimilarity()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = SentenceTransformer(\"sentence-transformers/all-MiniLM-L6-v2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer Relevance: 0.20\n"
     ]
    }
   ],
   "source": [
    "similarities = []\n",
    "for i, row in answer_relevance_checkpoint.iterrows():\n",
    "\n",
    "    original_question = row[\"original_question\"]\n",
    "    questions = row[\"questions\"]\n",
    "\n",
    "    original_question_embedding = model.encode(original_question)\n",
    "    questions_embedding = model.encode(questions)\n",
    "\n",
    "    similarity = cosine_similarity(\n",
    "        torch.tensor(original_question_embedding),\n",
    "        torch.tensor(questions_embedding),\n",
    "    ).mean()\n",
    "\n",
    "    similarities.append(similarity.item())\n",
    "\n",
    "print(f\"Answer Relevance: {sum(similarities) / len(answer_relevance_checkpoint):.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Context Relevance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [],
   "source": [
    "if os.path.exists(\"context_relevance_checkpoint.csv\"):\n",
    "    context_relevance_checkpoint = pd.read_csv(\"context_relevance_checkpoint.csv\")\n",
    "else:\n",
    "    context_relevance_checkpoint = pd.DataFrame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_context_relevance = \"\"\"\n",
    "Return relevante sentences from the provided context that can potentially\n",
    "help answer the following question. If no relevant sentences are found, or if you\n",
    "believe the question cannot be answered from the given context, return the phrase\n",
    "'Insufficient Information'. While extracting candidate sentences you’re not allowed\n",
    "to make any changes to sentences from given context.\n",
    "\n",
    "Your answer need to be only strings of the sentences split by \\n. Don't add any other information or special characters.\n",
    "\n",
    "Question:\n",
    "{question}\n",
    "\n",
    "Context:\n",
    "{context}\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "90bbbffe473a4331b2d84a69dcc566d6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/50 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "total_process = len(data_processed) - len(context_relevance_checkpoint)\n",
    "\n",
    "start_index = len(context_relevance_checkpoint)\n",
    "\n",
    "for i in tqdm(range(start_index, len(data_processed)), total=total_process):\n",
    "\n",
    "    row = data_processed[i]\n",
    "\n",
    "    question = row[\"question\"]\n",
    "    context = row[\"context\"]\n",
    "\n",
    "    prompt = prompt_context_relevance.format(\n",
    "        question=question,\n",
    "        context=\"\\n\".join([f\"{i+1} - {context}\" for i, context in enumerate(context)]),\n",
    "    )\n",
    "\n",
    "    context_relevance = predict_groq(prompt, temperature=1).split(\"\\n\")\n",
    "\n",
    "    context_relevance_checkpoint = pd.concat(\n",
    "        [\n",
    "            context_relevance_checkpoint,\n",
    "            pd.DataFrame(\n",
    "                {\n",
    "                    \"question\": [question],\n",
    "                    \"context\": [context],\n",
    "                    \"context_relevance\": [context_relevance],\n",
    "                }\n",
    "            ),\n",
    "        ],\n",
    "        ignore_index=True,\n",
    "    )\n",
    "\n",
    "    context_relevance_checkpoint.to_csv(\"context_relevance_checkpoint.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Context Relevance: 0.50\n"
     ]
    }
   ],
   "source": [
    "def remove_punctuation(text: str):\n",
    "    return text.translate(str.maketrans(\"\", \"\", string.punctuation))\n",
    "\n",
    "\n",
    "context_relevance_score = []\n",
    "\n",
    "for i, row in context_relevance_checkpoint.iterrows():\n",
    "\n",
    "    question = row[\"question\"]\n",
    "    context = row[\"context\"]\n",
    "\n",
    "    context_relevance = list(\n",
    "        map(lambda i: remove_punctuation(i.strip().lower()), row[\"context_relevance\"])\n",
    "    )\n",
    "\n",
    "    context_relevance = list(\n",
    "        filter(lambda i: i != \"insufficient information\", context_relevance)\n",
    "    )\n",
    "\n",
    "    context_relevance_score.append(len(context_relevance) / len(context))\n",
    "\n",
    "print(\n",
    "    f\"Context Relevance: {sum(context_relevance_score) / len(context_relevance_score):.2f}\"\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dl_venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
