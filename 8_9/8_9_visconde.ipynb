{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exerc√≠cio 8_9 Visconde\n",
    "\n",
    "matheusrdgsf@gmail.com / mrsf@cin.ufpe.br"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install groq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import Dataset, load_dataset, concatenate_datasets\n",
    "import os\n",
    "import getpass\n",
    "from groq import Groq\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import recall_score\n",
    "from tqdm.notebook import tqdm\n",
    "import pandas as pd\n",
    "import string\n",
    "from typing import List\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import json\n",
    "import tarfile\n",
    "from bs4 import BeautifulSoup\n",
    "import spacy\n",
    "from sentence_transformers import SentenceTransformer\n",
    "import torch\n",
    "import faiss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "if spacy.util.is_package(\"en_core_web_sm\"):\n",
    "    spacy_model = spacy.load(\"en_core_web_sm\")\n",
    "else:\n",
    "    !python -m spacy download en_core_web_sm\n",
    "    spacy_model = spacy.load(\"en_core_web_sm\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "N_QUESTIONS = 150"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LLM Inferecene"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "GROQ_KEY = os.getenv(\"GROQ_KEY\", getpass.getpass(\"Enter your Groq API key: \"))\n",
    "client = Groq(\n",
    "    api_key=GROQ_KEY,\n",
    ")\n",
    "MODELS = [\"llama3-70b-8192\", \"llama3-8b-8192\", \"mixtral-8x7b-32768\", \"gemma-7b-it\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_groq(text, retry=10):\n",
    "\n",
    "    for _ in range(retry):\n",
    "        try:\n",
    "            chat_completion = client.chat.completions.create(\n",
    "                messages=[\n",
    "                    {\n",
    "                        \"role\": \"user\",\n",
    "                        \"content\": f\"{text}\",\n",
    "                    }\n",
    "                ],\n",
    "                model=MODELS[0],\n",
    "                seed=42,\n",
    "                temperature=0,\n",
    "            )\n",
    "\n",
    "            return chat_completion.choices[0].message.content\n",
    "        except Exception as e:\n",
    "            print(e)\n",
    "            pass\n",
    "\n",
    "    return \"Fail in GROQ API.\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Download Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data downloaded and extracted successfully!\n"
     ]
    }
   ],
   "source": [
    "if not os.path.exists(\"data\"):\n",
    "\n",
    "    os.makedirs(\"data\")\n",
    "\n",
    "    !wget https://iirc-dataset.s3.us-west-2.amazonaws.com/iirc_train_dev.tgz -P data\n",
    "    !wget https://iirc-dataset.s3.us-west-2.amazonaws.com/context_articles.tar.gz -P data\n",
    "    !wget https://iirc-dataset.s3.us-west-2.amazonaws.com/iirc_test.json -P data\n",
    "\n",
    "    # Extract the data with tarfile\n",
    "    with tarfile.open(\"data/iirc_train_dev.tgz\", \"r:gz\") as tar:\n",
    "        tar.extractall(\"data\")\n",
    "\n",
    "    with tarfile.open(\"data/context_articles.tar.gz\", \"r:gz\") as tar:\n",
    "        tar.extractall(\"data\")\n",
    "\n",
    "    os.remove(\"data/iirc_train_dev.tgz\")\n",
    "    os.remove(\"data/context_articles.tar.gz\")\n",
    "\n",
    "print(\"Data downloaded and extracted successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "dev_data = load_dataset(\"json\", data_files=\"data/iirc_train_dev/dev.json\")\n",
    "test_data = load_dataset(\"json\", data_files=\"data/iirc_test.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "articles = json.load(open(\"data/context_articles.json\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Process data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data = test_data[\"train\"].select(range(N_QUESTIONS))\n",
    "dev_data = dev_data[\"train\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lower case and remove HTML tags\n",
    "test_data = test_data.map(\n",
    "    lambda x: {\n",
    "        \"text\": BeautifulSoup(x[\"text\"], \"html.parser\").get_text().lower(),\n",
    "        \"links\": list(\n",
    "            map(\n",
    "                lambda x: {\"indices\": x[\"indices\"], \"target\": x[\"target\"].lower()},\n",
    "                x[\"links\"],\n",
    "            )\n",
    "        ),\n",
    "        \"title\": x[\"title\"].lower(),\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get Docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "150\n",
      "2164\n"
     ]
    }
   ],
   "source": [
    "all_titles_dict = {i: j for i, j in zip(test_data[\"title\"], test_data[\"text\"])}\n",
    "\n",
    "print(len(all_titles_dict))\n",
    "\n",
    "for item in test_data[\"links\"]:\n",
    "    for target in item:\n",
    "        if target[\"target\"] not in all_titles_dict and target[\"target\"] in articles:\n",
    "            content = (\n",
    "                BeautifulSoup(articles[target[\"target\"]], \"html.parser\")\n",
    "                .get_text()\n",
    "                .lower()\n",
    "            )\n",
    "\n",
    "            all_titles_dict[target[\"target\"]] = content\n",
    "\n",
    "print(len(all_titles_dict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "titles, texts = zip(*all_titles_dict.items())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sentence Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm.auto import tqdm\n",
    "\n",
    "if os.path.exists(\"data/contents_list.csv\"):\n",
    "    contents_list = pd.read_csv(\"data/contents_list.csv\")[\"content\"].tolist()\n",
    "else:\n",
    "    contents_list = [\n",
    "        sent.text\n",
    "        for text in tqdm(texts, desc=\"Processing texts\")\n",
    "        for sent in spacy_model(text).sents\n",
    "    ]\n",
    "    pd.DataFrame({\"content\": contents_list}).to_csv(\n",
    "        \"data/contents_list.csv\", index=False\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Format questions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "questions_to_ask = []\n",
    "\n",
    "for i in range(len(test_data)):\n",
    "    pr = test_data[i][\"questions\"][0]\n",
    "    question = pr[\"question\"]\n",
    "    answer = pr[\"answer\"]\n",
    "    answer_type = answer[\"type\"]\n",
    "\n",
    "    if answer_type == \"binary\" or answer_type == \"value\":\n",
    "        final_answer = answer[\"answer_value\"]\n",
    "    elif answer_type == \"span\":\n",
    "        final_answer = answer[\"answer_spans\"][0][\"text\"]\n",
    "    elif answer_type == \"none\":\n",
    "        final_answer = \"none\"\n",
    "    else:\n",
    "        final_answer = \"An error perhaps, bad type\"\n",
    "        print(answer_type)\n",
    "\n",
    "    questions_to_ask.append({\"question\": question, \"answer\": final_answer})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'question': 'What is Zeus know for in Greek mythology?',\n",
       "  'answer': 'sky and thunder god'},\n",
       " {'question': 'How long had the First World War been over when Messe was named aide-de-camp?',\n",
       "  'answer': '5'},\n",
       " {'question': 'How long had Angela Scoular been acting professionally when she appeared in the movie \"On Her Majesty\\'s Secret Service\"?',\n",
       "  'answer': '2'}]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "questions_to_ask[:3]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Indexing Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SentenceTransformer(\n",
       "  (0): Transformer({'max_seq_length': 128, 'do_lower_case': False}) with Transformer model: BertModel \n",
       "  (1): Pooling({'word_embedding_dimension': 384, 'pooling_mode_cls_token': False, 'pooling_mode_mean_tokens': True, 'pooling_mode_max_tokens': False, 'pooling_mode_mean_sqrt_len_tokens': False, 'pooling_mode_weightedmean_tokens': False, 'pooling_mode_lasttoken': False, 'include_prompt': True})\n",
       ")"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = SentenceTransformer(\"paraphrase-MiniLM-L6-v2\")\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "if os.path.exists(\"data/embeddings.pt\"):\n",
    "    embeddings = torch.load(\"data/embeddings.pt\")\n",
    "else:\n",
    "    embeddings = model.encode(contents_list, show_progress_bar=True)\n",
    "    torch.save(embeddings, \"data/embeddings.pt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Indexing Faiss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "if os.path.exists(\"data/index.faiss\"):\n",
    "    index = faiss.read_index(\"data/index.bin\")\n",
    "else:\n",
    "    index = faiss.IndexFlatL2(embeddings.shape[1])\n",
    "    index.add(embeddings)\n",
    "    faiss.write_index(index, \"data/index.bin\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "How much money did IBM earn the year Delicious was founded? \n",
      "\n",
      "history.in the 1880s technologies emerged that would ultimately form the core of international business machines (ibm).\n",
      "the company also sponsored the olympic games from 1960‚Äì2000, and the national football league from 2003‚Äì2012.\n",
      "\n",
      "in 2012, ibm's brand was valued at $75.5 billion and ranked by interbrand as the second-best brand worldwide.\n",
      "finance.for the fiscal year 2017, ibm reported earnings of us$5.7 billion, with an annual revenue of us$79.1 billion, a decline of 1.0% over the previous fiscal cycle.\n",
      "also in 2015, ibm announced that it would go \"fabless\", continuing to design semiconductors, but offloading manufacturing to globalfoundries.\n",
      "\n",
      "nicknamed big blue, ibm is one of 30 companies included in the dow jones industrial average and one of the world's largest employers, with () over 350,000 employees, known as \"ibmers\".\n",
      "ibm hired its first black salesperson in 1946, and in 1952, ceo thomas j. watson, jr. published the company's first written equal opportunity policy letter, one year before the u.s. supreme court decision in brown vs. board of education and 11 years before the civil rights act of 1964.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Agradecimento Fabio Grasiotto\n",
    "def SentenceTransformer_getContext(question, base, k):\n",
    "\n",
    "    xq = model.encode([question])\n",
    "\n",
    "    _, I = index.search(xq, k)\n",
    "\n",
    "    str = \"\"\n",
    "\n",
    "    for i in range(0, k):\n",
    "\n",
    "        str = str + base[I[0][i]] + \"\\n\"\n",
    "\n",
    "    return str\n",
    "\n",
    "\n",
    "input_sequence = questions_to_ask[10].get(\"question\")\n",
    "\n",
    "\n",
    "print(input_sequence, \"\\n\")\n",
    "\n",
    "print(SentenceTransformer_getContext(input_sequence, contents_list, 5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluation comparing with Llama3-70b\n",
    "https://github.com/neuralmind-ai/visconde/blob/main/qasper_evaluator.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "import re\n",
    "\n",
    "\n",
    "def normalize_answer(s):\n",
    "    \"\"\"\n",
    "    Taken from the official evaluation script for v1.1 of the SQuAD dataset.\n",
    "    Lower text and remove punctuation, articles and extra whitespace.\n",
    "    \"\"\"\n",
    "\n",
    "    def remove_articles(text):\n",
    "        return re.sub(r\"\\b(a|an|the)\\b\", \" \", text)\n",
    "\n",
    "    def white_space_fix(text):\n",
    "        return \" \".join(text.split())\n",
    "\n",
    "    def remove_punc(text):\n",
    "        exclude = set(string.punctuation)\n",
    "        return \"\".join(ch for ch in text if ch not in exclude)\n",
    "\n",
    "    def lower(text):\n",
    "        return text.lower()\n",
    "\n",
    "    return white_space_fix(remove_articles(remove_punc(lower(s))))\n",
    "\n",
    "\n",
    "def token_f1_score(prediction, ground_truth):\n",
    "    \"\"\"\n",
    "    Taken from the official evaluation script for v1.1 of the SQuAD dataset.\n",
    "    \"\"\"\n",
    "    prediction_tokens = normalize_answer(prediction).split()\n",
    "    ground_truth_tokens = normalize_answer(ground_truth).split()\n",
    "    common = Counter(prediction_tokens) & Counter(ground_truth_tokens)\n",
    "    num_same = sum(common.values())\n",
    "    if num_same == 0:\n",
    "        return 0\n",
    "    precision = 1.0 * num_same / len(prediction_tokens)\n",
    "    recall = 1.0 * num_same / len(ground_truth_tokens)\n",
    "    f1 = (2 * precision * recall) / (precision + recall)\n",
    "    return f1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_llm_prompt(question):\n",
    "    prompt_template = \"\"\"\\\n",
    "Based on the following context, answer the following question. If the answer is not present in the context, please answer \"none\".\n",
    "Context:\\n{context}Question: {question}\\nAnswer:\"\"\"\n",
    "\n",
    "    context = SentenceTransformer_getContext(question, contents_list, 5)\n",
    "\n",
    "    prompt_template = prompt_template.format(\n",
    "        context=context.replace(\"\\n\\n\", \"\"), question=question\n",
    "    )\n",
    "\n",
    "    return prompt_template"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Based on the following context, answer the following question. If the answer is not present in the context, please answer \"none\".\n",
      "Context:\n",
      "history.the u.s. war department created the first antecedent of the u.s. air force, as a part of the u.s. army, on 1 august 1907, which through a succession of changes of organization, titles, and missions advanced toward eventual independence 40 years later.\n",
      "however, some of the terre irredente did not join the kingdom of italy until 1918 after italy defeated austria‚Äìhungary in world war i. for this reason, sometimes the period is extended to include the late 19th-century and the first world war (1915‚Äì1918), until the 4 november 1918 armistice of villa giusti, which is considered the completion of unification.\n",
      "in the episode \"captain parmenter, one man army,\" it is revealed that all of the soldiers (troopers) of \"f troop\" have been at fort courage for at least twenty months, meaning they spent at least part of the civil war there.\n",
      "names.the term \"first world war\" was first used in september 1914 by german biologist and philosopher ernst haeckel, who claimed that \"there is no doubt that the course and character of the feared 'european war'¬†... will become the first world war in the full sense of the word,\" citing a wire service report in the indianapolis star on 20 september 1914.\n",
      "sources.- art of war symposium, from the dnepr to the vistula: soviet offensive operations ‚Äì november 1943 ‚Äì august 1944, a transcript of proceedings, center for land warfare, us army war college, 29 april ‚Äì 3 may 1985, col. d.m. glantz ed., fort leavewnworth, kansas, 1992\n",
      "- ziemke, e.f. stalingrad to berlin: the german defeat in the east, office of the chief of military history, u.s. army; 1st edition, washington d.c., 1968\n",
      "- roper, steven d. romania: the unfinished revolution (postcommunist states and nations), routledge; 1 edition, 2000,\n",
      "- vladimir tismƒÉneanu, stalinism for all seasons: a political history of romanian communism, university of california press, berkeley, 2003, p.¬†86.\n",
      "Question: How long had the First World War been over when Messe was named aide-de-camp?\n",
      "Answer:\n"
     ]
    }
   ],
   "source": [
    "print(create_llm_prompt(questions_to_ask[1][\"question\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b233cb8b43ba4a9d9148e67896bd3b6f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Processing questions:   0%|          | 0/150 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "results = []\n",
    "\n",
    "for item in tqdm(questions_to_ask, desc=\"Processing questions\"):\n",
    "\n",
    "    question = item.get(\"question\")\n",
    "\n",
    "    answer = normalize_answer(item.get(\"answer\"))\n",
    "\n",
    "    model_answer = normalize_answer(predict_groq(create_llm_prompt(question)))\n",
    "\n",
    "    f1_score = token_f1_score(model_answer, answer)\n",
    "\n",
    "    exact_match = 1 if model_answer == answer else 0\n",
    "\n",
    "    results.append(\n",
    "        {\n",
    "            \"question\": question,\n",
    "            \"answer\": answer,\n",
    "            \"model_answer\": model_answer,\n",
    "            \"f1_score\": f1_score,\n",
    "            \"exact_match\": exact_match,\n",
    "        }\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_df = pd.DataFrame(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>question</th>\n",
       "      <th>answer</th>\n",
       "      <th>model_answer</th>\n",
       "      <th>f1_score</th>\n",
       "      <th>exact_match</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>What is Zeus know for in Greek mythology?</td>\n",
       "      <td>sky and thunder god</td>\n",
       "      <td>according to context zeus is known as sky and ...</td>\n",
       "      <td>0.421053</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>How long had the First World War been over whe...</td>\n",
       "      <td>5</td>\n",
       "      <td>none</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>How long had Angela Scoular been acting profes...</td>\n",
       "      <td>2</td>\n",
       "      <td>none</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>What is the capacity of the stadium where Brun...</td>\n",
       "      <td>26688</td>\n",
       "      <td>none</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>In which country was Wilhelm M√ºller born?</td>\n",
       "      <td>germany</td>\n",
       "      <td>germany</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>145</th>\n",
       "      <td>Which of the destinations had the largest popu...</td>\n",
       "      <td>none</td>\n",
       "      <td>none</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>146</th>\n",
       "      <td>Was Rao alive when Manmohan Singh was prime mi...</td>\n",
       "      <td>yes</td>\n",
       "      <td>none</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>147</th>\n",
       "      <td>Who was in charge of the London County Council...</td>\n",
       "      <td>municipal reformers</td>\n",
       "      <td>none context does not mention who was in charg...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>148</th>\n",
       "      <td>How many years passed between the sack of Cons...</td>\n",
       "      <td>4</td>\n",
       "      <td>none context does not mention sack of constant...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>149</th>\n",
       "      <td>How many weeks did \"What Hurts the Most\" spend...</td>\n",
       "      <td>none</td>\n",
       "      <td>according to context what hurts most spent 1 w...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>150 rows √ó 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              question               answer  \\\n",
       "0            What is Zeus know for in Greek mythology?  sky and thunder god   \n",
       "1    How long had the First World War been over whe...                    5   \n",
       "2    How long had Angela Scoular been acting profes...                    2   \n",
       "3    What is the capacity of the stadium where Brun...                26688   \n",
       "4            In which country was Wilhelm M√ºller born?              germany   \n",
       "..                                                 ...                  ...   \n",
       "145  Which of the destinations had the largest popu...                 none   \n",
       "146  Was Rao alive when Manmohan Singh was prime mi...                  yes   \n",
       "147  Who was in charge of the London County Council...  municipal reformers   \n",
       "148  How many years passed between the sack of Cons...                    4   \n",
       "149  How many weeks did \"What Hurts the Most\" spend...                 none   \n",
       "\n",
       "                                          model_answer  f1_score  exact_match  \n",
       "0    according to context zeus is known as sky and ...  0.421053            0  \n",
       "1                                                 none  0.000000            0  \n",
       "2                                                 none  0.000000            0  \n",
       "3                                                 none  0.000000            0  \n",
       "4                                              germany  1.000000            1  \n",
       "..                                                 ...       ...          ...  \n",
       "145                                               none  1.000000            1  \n",
       "146                                               none  0.000000            0  \n",
       "147  none context does not mention who was in charg...  0.000000            0  \n",
       "148  none context does not mention sack of constant...  0.000000            0  \n",
       "149  according to context what hurts most spent 1 w...  0.000000            0  \n",
       "\n",
       "[150 rows x 5 columns]"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>f1_score</th>\n",
       "      <th>exact_match</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>150.000000</td>\n",
       "      <td>150.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.242816</td>\n",
       "      <td>0.213333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.406838</td>\n",
       "      <td>0.411034</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.264286</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         f1_score  exact_match\n",
       "count  150.000000   150.000000\n",
       "mean     0.242816     0.213333\n",
       "std      0.406838     0.411034\n",
       "min      0.000000     0.000000\n",
       "25%      0.000000     0.000000\n",
       "50%      0.000000     0.000000\n",
       "75%      0.264286     0.000000\n",
       "max      1.000000     1.000000"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# mean f1 score and exact match\n",
    "results_df[[\"f1_score\", \"exact_match\"]].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_df.to_csv(\"results.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dl_venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
