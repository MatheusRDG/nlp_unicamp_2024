{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercício 8_9 Visconde\n",
    "\n",
    "matheusrdgsf@gmail.com / mrsf@cin.ufpe.br"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install groq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import Dataset, load_dataset, concatenate_datasets\n",
    "import os\n",
    "import getpass\n",
    "from groq import Groq\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import recall_score\n",
    "from tqdm.notebook import tqdm\n",
    "import pandas as pd\n",
    "import string\n",
    "from typing import List\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import json\n",
    "import tarfile\n",
    "from bs4 import BeautifulSoup\n",
    "import spacy\n",
    "from sentence_transformers import SentenceTransformer\n",
    "import torch\n",
    "import faiss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "if spacy.util.is_package(\"en_core_web_sm\"):\n",
    "    spacy_model = spacy.load(\"en_core_web_sm\")\n",
    "else:\n",
    "    !python -m spacy download en_core_web_sm\n",
    "    spacy_model = spacy.load(\"en_core_web_sm\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "N_QUESTIONS = 150"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LLM Inferecene"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "GROQ_KEY = os.getenv(\"GROQ_KEY\", getpass.getpass(\"Enter your Groq API key: \"))\n",
    "client = Groq(\n",
    "    api_key=GROQ_KEY,\n",
    ")\n",
    "MODELS = [\"llama3-70b-8192\", \"llama3-8b-8192\", \"mixtral-8x7b-32768\", \"gemma-7b-it\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_groq(text, retry=10):\n",
    "\n",
    "    for _ in range(retry):\n",
    "        try:\n",
    "            chat_completion = client.chat.completions.create(\n",
    "                messages=[\n",
    "                    {\n",
    "                        \"role\": \"user\",\n",
    "                        \"content\": f\"{text}\",\n",
    "                    }\n",
    "                ],\n",
    "                model=MODELS[0],\n",
    "                seed=42,\n",
    "                temperature=0,\n",
    "            )\n",
    "\n",
    "            return chat_completion.choices[0].message.content\n",
    "        except Exception as e:\n",
    "            print(e)\n",
    "            pass\n",
    "\n",
    "    return \"Fail in GROQ API.\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Download Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data downloaded and extracted successfully!\n"
     ]
    }
   ],
   "source": [
    "if not os.path.exists(\"data\"):\n",
    "\n",
    "    os.makedirs(\"data\")\n",
    "\n",
    "    !wget https://iirc-dataset.s3.us-west-2.amazonaws.com/iirc_train_dev.tgz -P data\n",
    "    !wget https://iirc-dataset.s3.us-west-2.amazonaws.com/context_articles.tar.gz -P data\n",
    "    !wget https://iirc-dataset.s3.us-west-2.amazonaws.com/iirc_test.json -P data\n",
    "\n",
    "    # Extract the data with tarfile\n",
    "    with tarfile.open(\"data/iirc_train_dev.tgz\", \"r:gz\") as tar:\n",
    "        tar.extractall(\"data\")\n",
    "\n",
    "    with tarfile.open(\"data/context_articles.tar.gz\", \"r:gz\") as tar:\n",
    "        tar.extractall(\"data\")\n",
    "\n",
    "    os.remove(\"data/iirc_train_dev.tgz\")\n",
    "    os.remove(\"data/context_articles.tar.gz\")\n",
    "\n",
    "print(\"Data downloaded and extracted successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "dev_data = load_dataset(\"json\", data_files=\"data/iirc_train_dev/dev.json\")\n",
    "test_data = load_dataset(\"json\", data_files=\"data/iirc_test.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "articles = json.load(open(\"data/context_articles.json\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Process data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data = test_data[\"train\"].select(range(N_QUESTIONS))\n",
    "dev_data = dev_data[\"train\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lower case and remove HTML tags\n",
    "test_data = test_data.map(\n",
    "    lambda x: {\n",
    "        \"text\": BeautifulSoup(x[\"text\"], \"html.parser\").get_text().lower(),\n",
    "        \"links\": list(\n",
    "            map(\n",
    "                lambda x: {\"indices\": x[\"indices\"], \"target\": x[\"target\"].lower()},\n",
    "                x[\"links\"],\n",
    "            )\n",
    "        ),\n",
    "        \"title\": x[\"title\"].lower(),\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get Docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "150\n",
      "2164\n"
     ]
    }
   ],
   "source": [
    "all_titles_dict = {i: j for i, j in zip(test_data[\"title\"], test_data[\"text\"])}\n",
    "\n",
    "print(len(all_titles_dict))\n",
    "\n",
    "for item in test_data[\"links\"]:\n",
    "    for target in item:\n",
    "        if target[\"target\"] not in all_titles_dict and target[\"target\"] in articles:\n",
    "            content = (\n",
    "                BeautifulSoup(articles[target[\"target\"]], \"html.parser\")\n",
    "                .get_text()\n",
    "                .lower()\n",
    "            )\n",
    "\n",
    "            all_titles_dict[target[\"target\"]] = content\n",
    "\n",
    "print(len(all_titles_dict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "titles, texts = zip(*all_titles_dict.items())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sentence Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm.auto import tqdm\n",
    "\n",
    "if os.path.exists(\"data/contents_list.csv\"):\n",
    "    contents_list = pd.read_csv(\"data/contents_list.csv\")[\"content\"].tolist()\n",
    "else:\n",
    "    contents_list = [\n",
    "        sent.text\n",
    "        for text in tqdm(texts, desc=\"Processing texts\")\n",
    "        for sent in spacy_model(text).sents\n",
    "    ]\n",
    "    pd.DataFrame({\"content\": contents_list}).to_csv(\n",
    "        \"data/contents_list.csv\", index=False\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Format questions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "questions_to_ask = []\n",
    "\n",
    "for i in range(len(test_data)):\n",
    "    pr = test_data[i][\"questions\"][0]\n",
    "    question = pr[\"question\"]\n",
    "    answer = pr[\"answer\"]\n",
    "    answer_type = answer[\"type\"]\n",
    "\n",
    "    if answer_type == \"binary\" or answer_type == \"value\":\n",
    "        final_answer = answer[\"answer_value\"]\n",
    "    elif answer_type == \"span\":\n",
    "        final_answer = answer[\"answer_spans\"][0][\"text\"]\n",
    "    elif answer_type == \"none\":\n",
    "        final_answer = \"none\"\n",
    "    else:\n",
    "        final_answer = \"An error perhaps, bad type\"\n",
    "        print(answer_type)\n",
    "\n",
    "    questions_to_ask.append({\"question\": question, \"answer\": final_answer})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'question': 'What is Zeus know for in Greek mythology?',\n",
       "  'answer': 'sky and thunder god'},\n",
       " {'question': 'How long had the First World War been over when Messe was named aide-de-camp?',\n",
       "  'answer': '5'},\n",
       " {'question': 'How long had Angela Scoular been acting professionally when she appeared in the movie \"On Her Majesty\\'s Secret Service\"?',\n",
       "  'answer': '2'}]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "questions_to_ask[:3]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Indexing Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4ac4f6d7920b435abfb0bfd91cbf8f56",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "modules.json:   0%|          | 0.00/349 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d24ed1953a0e4f058b759b2692a82929",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config_sentence_transformers.json:   0%|          | 0.00/116 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "31146fc382804debaa9f2f1a09940f8f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "README.md:   0%|          | 0.00/10.7k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c9904f7741134ed3ab0d4960bd400798",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "sentence_bert_config.json:   0%|          | 0.00/53.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fae6e564a1a64b56b47dd2ebe4cd85b6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/615 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d1bca13e26a0410cad6d09b29cf47d7b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/133M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0d8a651fec814e5fa09d295be52ed42f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/352 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b3050036da85404f8c012e484a622d06",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "373ec872e9db4e8684fe9ca21ed48d35",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/466k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "41c2d712cd5540ba81375f305cae0207",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/112 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cb19671c83224aaea2be6e60cc5315db",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "1_Pooling/config.json:   0%|          | 0.00/190 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "SentenceTransformer(\n",
       "  (0): Transformer({'max_seq_length': 128, 'do_lower_case': False}) with Transformer model: BertModel \n",
       "  (1): Pooling({'word_embedding_dimension': 384, 'pooling_mode_cls_token': False, 'pooling_mode_mean_tokens': True, 'pooling_mode_max_tokens': False, 'pooling_mode_mean_sqrt_len_tokens': False, 'pooling_mode_weightedmean_tokens': False, 'pooling_mode_lasttoken': False, 'include_prompt': True})\n",
       "  (2): Normalize()\n",
       ")"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = SentenceTransformer(\"sentence-transformers/all-MiniLM-L12-v2\")\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "843b4adbef3144afaf507247fe1738cd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/9036 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "if os.path.exists(\"data/embeddings.pt\"):\n",
    "    embeddings = torch.load(\"data/embeddings.pt\")\n",
    "else:\n",
    "    embeddings = model.encode(contents_list, show_progress_bar=True)\n",
    "    torch.save(embeddings, \"data/embeddings.pt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Indexing Faiss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "if os.path.exists(\"data/index.bin\"):\n",
    "    index = faiss.read_index(\"data/index.bin\")\n",
    "else:\n",
    "    index = faiss.IndexFlatL2(embeddings.shape[1])\n",
    "    index.add(embeddings)\n",
    "    faiss.write_index(index, \"data/index.bin\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "How much money did IBM earn the year Delicious was founded? \n",
      "\n",
      "finance.for the fiscal year 2017, ibm reported earnings of us$5.7 billion, with an annual revenue of us$79.1 billion, a decline of 1.0% over the previous fiscal cycle.\n",
      "the company also sponsored the olympic games from 1960–2000, and the national football league from 2003–2012.\n",
      "\n",
      "in 2012, ibm's brand was valued at $75.5 billion and ranked by interbrand as the second-best brand worldwide.\n",
      "ibm is also a major research organization, holding the record for most u.s. patents generated by a business () for 26 consecutive years.\n",
      "ibm has a valuable brand as a result of over 100 years of operations and marketing campaigns.\n",
      "in march 2005, he left his day job to work on delicious full-time, and in april 2005 it received approximately $2 million in funding from investors including union square ventures and amazon.com.\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Agradecimento Fabio Grasiotto\n",
    "def SentenceTransformer_getContext(question, base, k):\n",
    "\n",
    "    xq = model.encode([question])\n",
    "\n",
    "    _, I = index.search(xq, k)\n",
    "\n",
    "    str = \"\"\n",
    "\n",
    "    for i in range(0, k):\n",
    "\n",
    "        str = str + base[I[0][i]] + \"\\n\"\n",
    "\n",
    "    return str\n",
    "\n",
    "\n",
    "input_sequence = questions_to_ask[10].get(\"question\")\n",
    "\n",
    "\n",
    "print(input_sequence, \"\\n\")\n",
    "\n",
    "print(SentenceTransformer_getContext(input_sequence, contents_list, 5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluation comparing with Llama3-70b\n",
    "https://github.com/neuralmind-ai/visconde/blob/main/qasper_evaluator.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "import re\n",
    "\n",
    "\n",
    "def normalize_answer(s):\n",
    "    \"\"\"\n",
    "    Taken from the official evaluation script for v1.1 of the SQuAD dataset.\n",
    "    Lower text and remove punctuation, articles and extra whitespace.\n",
    "    \"\"\"\n",
    "\n",
    "    def remove_articles(text):\n",
    "        return re.sub(r\"\\b(a|an|the)\\b\", \" \", text)\n",
    "\n",
    "    def white_space_fix(text):\n",
    "        return \" \".join(text.split())\n",
    "\n",
    "    def remove_punc(text):\n",
    "        exclude = set(string.punctuation)\n",
    "        return \"\".join(ch for ch in text if ch not in exclude)\n",
    "\n",
    "    def lower(text):\n",
    "        return text.lower()\n",
    "\n",
    "    return white_space_fix(remove_articles(remove_punc(lower(s))))\n",
    "\n",
    "\n",
    "def token_f1_score(prediction, ground_truth):\n",
    "    \"\"\"\n",
    "    Taken from the official evaluation script for v1.1 of the SQuAD dataset.\n",
    "    \"\"\"\n",
    "    prediction_tokens = normalize_answer(prediction).split()\n",
    "    ground_truth_tokens = normalize_answer(ground_truth).split()\n",
    "    common = Counter(prediction_tokens) & Counter(ground_truth_tokens)\n",
    "    num_same = sum(common.values())\n",
    "    if num_same == 0:\n",
    "        return 0\n",
    "    precision = 1.0 * num_same / len(prediction_tokens)\n",
    "    recall = 1.0 * num_same / len(ground_truth_tokens)\n",
    "    f1 = (2 * precision * recall) / (precision + recall)\n",
    "    return f1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_llm_prompt(question):\n",
    "    prompt_template = \"\"\"\\\n",
    "Based on the following context, answer the following question. If the answer is not present in the context, please answer \"none\".\n",
    "Context:\\n{context}Question: {question}\\nAnswer:\"\"\"\n",
    "\n",
    "    context = SentenceTransformer_getContext(question, contents_list, 5)\n",
    "\n",
    "    prompt_template = prompt_template.format(\n",
    "        context=context.replace(\"\\n\\n\", \"\"), question=question\n",
    "    )\n",
    "\n",
    "    return prompt_template"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Based on the following context, answer the following question. If the answer is not present in the context, please answer \"none\".\n",
      "Context:\n",
      "first world war.over\n",
      "he was a brevet colonel at the end of the war.\n",
      "it was important during the english civil war and was the site of a prisoner of war camp during the first world war.\n",
      "inter-war period.\n",
      "the camps were abolished after world war ii.\n",
      "Question: How long had the First World War been over when Messe was named aide-de-camp?\n",
      "Answer:\n"
     ]
    }
   ],
   "source": [
    "print(create_llm_prompt(questions_to_ask[1][\"question\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "34231dc79f24404c9707fad76b016249",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Processing questions:   0%|          | 0/150 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "results = []\n",
    "\n",
    "for item in tqdm(questions_to_ask, desc=\"Processing questions\"):\n",
    "\n",
    "    question = item.get(\"question\")\n",
    "\n",
    "    answer = normalize_answer(item.get(\"answer\"))\n",
    "\n",
    "    model_answer = normalize_answer(predict_groq(create_llm_prompt(question)))\n",
    "\n",
    "    f1_score = token_f1_score(model_answer, answer)\n",
    "\n",
    "    exact_match = 1 if model_answer == answer else 0\n",
    "\n",
    "    results.append(\n",
    "        {\n",
    "            \"question\": question,\n",
    "            \"answer\": answer,\n",
    "            \"model_answer\": model_answer,\n",
    "            \"f1_score\": f1_score,\n",
    "            \"exact_match\": exact_match,\n",
    "        }\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_df = pd.DataFrame(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>question</th>\n",
       "      <th>answer</th>\n",
       "      <th>model_answer</th>\n",
       "      <th>f1_score</th>\n",
       "      <th>exact_match</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>What is Zeus know for in Greek mythology?</td>\n",
       "      <td>sky and thunder god</td>\n",
       "      <td>zeus is known for his erotic escapades</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>How long had the First World War been over whe...</td>\n",
       "      <td>5</td>\n",
       "      <td>none</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>How long had Angela Scoular been acting profes...</td>\n",
       "      <td>2</td>\n",
       "      <td>25 years</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>What is the capacity of the stadium where Brun...</td>\n",
       "      <td>26688</td>\n",
       "      <td>none</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>In which country was Wilhelm Müller born?</td>\n",
       "      <td>germany</td>\n",
       "      <td>germany</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>In which Italian region did Pesce studied medi...</td>\n",
       "      <td>liguria</td>\n",
       "      <td>liguria</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>What albums were ranked higher than \"It Takes ...</td>\n",
       "      <td>none</td>\n",
       "      <td>none</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>When was the sports organization that the Turk...</td>\n",
       "      <td>1909</td>\n",
       "      <td>none</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>When was the port established at the Port Phil...</td>\n",
       "      <td>none</td>\n",
       "      <td>none</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>At which tournament were more goals scored, 19...</td>\n",
       "      <td>none</td>\n",
       "      <td>none</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>How much money did IBM earn the year Delicious...</td>\n",
       "      <td>none</td>\n",
       "      <td>year delicious was founded is not mentioned in...</td>\n",
       "      <td>0.142857</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>How many years had Mike Elizondo been a produc...</td>\n",
       "      <td>none</td>\n",
       "      <td>none</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>How long had Alex Rance been a professional pl...</td>\n",
       "      <td>11</td>\n",
       "      <td>none</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>In what country is the city located where the ...</td>\n",
       "      <td>iraq</td>\n",
       "      <td>none</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>How many years were there between Pompeii's de...</td>\n",
       "      <td>1897</td>\n",
       "      <td>none</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Which university did Don Branby played college...</td>\n",
       "      <td>colorado buffaloes</td>\n",
       "      <td>colorado</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>How long had the Perthshire Regiment been a go...</td>\n",
       "      <td>69</td>\n",
       "      <td>none there is no mention of person named haris...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>When was the university where Tookey served as...</td>\n",
       "      <td>none</td>\n",
       "      <td>none</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>Which team won the first game in the 2004 Nati...</td>\n",
       "      <td>cardinals</td>\n",
       "      <td>none</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>Which is the oldest of the schools where Stirn...</td>\n",
       "      <td>none</td>\n",
       "      <td>fairleigh dickinson university 1900</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>How long had Mystic Records been in business w...</td>\n",
       "      <td>none</td>\n",
       "      <td>none context does not provide information on w...</td>\n",
       "      <td>0.050000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>How much money did the Dallas Burn spend in to...</td>\n",
       "      <td>none</td>\n",
       "      <td>none</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>How many championship appearances has the team...</td>\n",
       "      <td>5</td>\n",
       "      <td>none</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>How long is the most important river of  the C...</td>\n",
       "      <td>none</td>\n",
       "      <td>none</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>Had the Chicago White Sox been around longer t...</td>\n",
       "      <td>yes</td>\n",
       "      <td>none</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>How old was the person who shot Waitkus the ye...</td>\n",
       "      <td>20</td>\n",
       "      <td>19</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>In what race was Sohn Kee-chung the gold medal...</td>\n",
       "      <td>marathon</td>\n",
       "      <td>answer is marathon</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>Was Eduard van Beinum still alive whnen Gilmor...</td>\n",
       "      <td>no</td>\n",
       "      <td>none</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>What percentage of the Philippine Revolutionar...</td>\n",
       "      <td>none</td>\n",
       "      <td>none</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>How far away from Lewis' birthplace was the ho...</td>\n",
       "      <td>none</td>\n",
       "      <td>none</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>Which of the battles Sherman fought during a w...</td>\n",
       "      <td>donelson</td>\n",
       "      <td>none</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>Which country did some of the tribes escaped t...</td>\n",
       "      <td>united states</td>\n",
       "      <td>answer is united states specifically southern ...</td>\n",
       "      <td>0.444444</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>In what county did Hirsch study under Edward C...</td>\n",
       "      <td>united states</td>\n",
       "      <td>alameda county university of california berkel...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>What states do the roads that go around flathe...</td>\n",
       "      <td>arizona</td>\n",
       "      <td>none</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>What is the birthplace of the person who used ...</td>\n",
       "      <td>normandy france</td>\n",
       "      <td>none</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>How many students were enrolled at the Lomonos...</td>\n",
       "      <td>none</td>\n",
       "      <td>none</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>Of the schools where Bernard Avishai taught, w...</td>\n",
       "      <td>duke university</td>\n",
       "      <td>none context does not mention bernard avishai ...</td>\n",
       "      <td>0.068966</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>Of the universities where Paranikas studied, w...</td>\n",
       "      <td>university of munich</td>\n",
       "      <td>none</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>Is Josh Heupel older than Scott Frost?</td>\n",
       "      <td>no</td>\n",
       "      <td>based on context scott frost was born on janua...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>How long had Gorbacheve been in power before t...</td>\n",
       "      <td>6</td>\n",
       "      <td>none</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>How many months was the Northwest Indian War?</td>\n",
       "      <td>120</td>\n",
       "      <td>answer is not present in context so answer is ...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>In what city was Romeo's father born?</td>\n",
       "      <td>new orleans</td>\n",
       "      <td>none</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>How long had the Spruce Grove Mets been a team...</td>\n",
       "      <td>1</td>\n",
       "      <td>answer is not present in context so answer is ...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>Which team won the 1964 championship where Swi...</td>\n",
       "      <td>none</td>\n",
       "      <td>none</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>Which singer was younger when they recorded a ...</td>\n",
       "      <td>nivek ogre</td>\n",
       "      <td>none</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>What was the first named storm of the 2019 hur...</td>\n",
       "      <td>andrea</td>\n",
       "      <td>none</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>What was the construction cost of the stadium ...</td>\n",
       "      <td>455 million</td>\n",
       "      <td>answer is 4547 million 3023 million 1432 milli...</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>How long had the French Foreign Legion been in...</td>\n",
       "      <td>none</td>\n",
       "      <td>none</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>What is the population of the island nation th...</td>\n",
       "      <td>332634</td>\n",
       "      <td>none</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>In what months did Hurricane Katrine and Hurri...</td>\n",
       "      <td>august 2005</td>\n",
       "      <td>answer is not present in context so answer is ...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             question                answer  \\\n",
       "0           What is Zeus know for in Greek mythology?   sky and thunder god   \n",
       "1   How long had the First World War been over whe...                     5   \n",
       "2   How long had Angela Scoular been acting profes...                     2   \n",
       "3   What is the capacity of the stadium where Brun...                 26688   \n",
       "4           In which country was Wilhelm Müller born?               germany   \n",
       "5   In which Italian region did Pesce studied medi...               liguria   \n",
       "6   What albums were ranked higher than \"It Takes ...                  none   \n",
       "7   When was the sports organization that the Turk...                  1909   \n",
       "8   When was the port established at the Port Phil...                  none   \n",
       "9   At which tournament were more goals scored, 19...                  none   \n",
       "10  How much money did IBM earn the year Delicious...                  none   \n",
       "11  How many years had Mike Elizondo been a produc...                  none   \n",
       "12  How long had Alex Rance been a professional pl...                    11   \n",
       "13  In what country is the city located where the ...                  iraq   \n",
       "14  How many years were there between Pompeii's de...                  1897   \n",
       "15  Which university did Don Branby played college...    colorado buffaloes   \n",
       "16  How long had the Perthshire Regiment been a go...                    69   \n",
       "17  When was the university where Tookey served as...                  none   \n",
       "18  Which team won the first game in the 2004 Nati...             cardinals   \n",
       "19  Which is the oldest of the schools where Stirn...                  none   \n",
       "20  How long had Mystic Records been in business w...                  none   \n",
       "21  How much money did the Dallas Burn spend in to...                  none   \n",
       "22  How many championship appearances has the team...                     5   \n",
       "23  How long is the most important river of  the C...                  none   \n",
       "24  Had the Chicago White Sox been around longer t...                   yes   \n",
       "25  How old was the person who shot Waitkus the ye...                    20   \n",
       "26  In what race was Sohn Kee-chung the gold medal...              marathon   \n",
       "27  Was Eduard van Beinum still alive whnen Gilmor...                    no   \n",
       "28  What percentage of the Philippine Revolutionar...                  none   \n",
       "29  How far away from Lewis' birthplace was the ho...                  none   \n",
       "30  Which of the battles Sherman fought during a w...              donelson   \n",
       "31  Which country did some of the tribes escaped t...         united states   \n",
       "32  In what county did Hirsch study under Edward C...         united states   \n",
       "33  What states do the roads that go around flathe...               arizona   \n",
       "34  What is the birthplace of the person who used ...       normandy france   \n",
       "35  How many students were enrolled at the Lomonos...                  none   \n",
       "36  Of the schools where Bernard Avishai taught, w...       duke university   \n",
       "37  Of the universities where Paranikas studied, w...  university of munich   \n",
       "38             Is Josh Heupel older than Scott Frost?                    no   \n",
       "39  How long had Gorbacheve been in power before t...                     6   \n",
       "40      How many months was the Northwest Indian War?                   120   \n",
       "41              In what city was Romeo's father born?           new orleans   \n",
       "42  How long had the Spruce Grove Mets been a team...                     1   \n",
       "43  Which team won the 1964 championship where Swi...                  none   \n",
       "44  Which singer was younger when they recorded a ...            nivek ogre   \n",
       "45  What was the first named storm of the 2019 hur...                andrea   \n",
       "46  What was the construction cost of the stadium ...           455 million   \n",
       "47  How long had the French Foreign Legion been in...                  none   \n",
       "48  What is the population of the island nation th...                332634   \n",
       "49  In what months did Hurricane Katrine and Hurri...           august 2005   \n",
       "\n",
       "                                         model_answer  f1_score  exact_match  \n",
       "0              zeus is known for his erotic escapades  0.000000            0  \n",
       "1                                                none  0.000000            0  \n",
       "2                                            25 years  0.000000            0  \n",
       "3                                                none  0.000000            0  \n",
       "4                                             germany  1.000000            1  \n",
       "5                                             liguria  1.000000            1  \n",
       "6                                                none  1.000000            1  \n",
       "7                                                none  0.000000            0  \n",
       "8                                                none  1.000000            1  \n",
       "9                                                none  1.000000            1  \n",
       "10  year delicious was founded is not mentioned in...  0.142857            0  \n",
       "11                                               none  1.000000            1  \n",
       "12                                               none  0.000000            0  \n",
       "13                                               none  0.000000            0  \n",
       "14                                               none  0.000000            0  \n",
       "15                                           colorado  0.666667            0  \n",
       "16  none there is no mention of person named haris...  0.000000            0  \n",
       "17                                               none  1.000000            1  \n",
       "18                                               none  0.000000            0  \n",
       "19                fairleigh dickinson university 1900  0.000000            0  \n",
       "20  none context does not provide information on w...  0.050000            0  \n",
       "21                                               none  1.000000            1  \n",
       "22                                               none  0.000000            0  \n",
       "23                                               none  1.000000            1  \n",
       "24                                               none  0.000000            0  \n",
       "25                                                 19  0.000000            0  \n",
       "26                                 answer is marathon  0.500000            0  \n",
       "27                                               none  0.000000            0  \n",
       "28                                               none  1.000000            1  \n",
       "29                                               none  1.000000            1  \n",
       "30                                               none  0.000000            0  \n",
       "31  answer is united states specifically southern ...  0.444444            0  \n",
       "32  alameda county university of california berkel...  0.000000            0  \n",
       "33                                               none  0.000000            0  \n",
       "34                                               none  0.000000            0  \n",
       "35                                               none  1.000000            1  \n",
       "36  none context does not mention bernard avishai ...  0.068966            0  \n",
       "37                                               none  0.000000            0  \n",
       "38  based on context scott frost was born on janua...  0.000000            0  \n",
       "39                                               none  0.000000            0  \n",
       "40  answer is not present in context so answer is ...  0.000000            0  \n",
       "41                                               none  0.000000            0  \n",
       "42  answer is not present in context so answer is ...  0.000000            0  \n",
       "43                                               none  1.000000            1  \n",
       "44                                               none  0.000000            0  \n",
       "45                                               none  0.000000            0  \n",
       "46  answer is 4547 million 3023 million 1432 milli...  0.166667            0  \n",
       "47                                               none  1.000000            1  \n",
       "48                                               none  0.000000            0  \n",
       "49  answer is not present in context so answer is ...  0.000000            0  "
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_df.head(50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>f1_score</th>\n",
       "      <th>exact_match</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>150.000000</td>\n",
       "      <td>150.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.324852</td>\n",
       "      <td>0.273333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.443616</td>\n",
       "      <td>0.447164</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         f1_score  exact_match\n",
       "count  150.000000   150.000000\n",
       "mean     0.324852     0.273333\n",
       "std      0.443616     0.447164\n",
       "min      0.000000     0.000000\n",
       "25%      0.000000     0.000000\n",
       "50%      0.000000     0.000000\n",
       "75%      1.000000     1.000000\n",
       "max      1.000000     1.000000"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# mean f1 score and exact match\n",
    "results_df[[\"f1_score\", \"exact_match\"]].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_df.to_csv(\"results.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dl_venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
